"""Public programmatic API for OpenSloth."""
from __future__ import annotations

from pathlib import Path
from typing import Tuple
import json
import tempfile
import textwrap
import os

from opensloth.opensloth_config import OpenSlothConfig, TrainingArguments
from opensloth.scripts.opensloth_trainer import (
    run_mp_training,
    setup_envs,
    run_tmux_training,
)

def _serialise_configs_to_temp(opensloth_config: OpenSlothConfig, training_args: TrainingArguments) -> Path:
    tmp_dir = Path(tempfile.mkdtemp(prefix="opensloth_cli_"))
    cfg_path = tmp_dir / "_tmux_config.py"
    code = textwrap.dedent(
        f"""# Auto-generated by OpenSloth API (tmux launch)
import json
from opensloth.opensloth_config import OpenSlothConfig, TrainingArguments
_opensloth_cfg_json = r'''{json.dumps(opensloth_config.model_dump())}'''
_training_args_json = r'''{json.dumps(training_args.model_dump())}'''
opensloth_config = OpenSlothConfig(**json.loads(_opensloth_cfg_json))
training_config = TrainingArguments(**json.loads(_training_args_json))
"""
    )
    cfg_path.write_text(code)
    return cfg_path

def run_training(
    opensloth_config: OpenSlothConfig,
    training_args: TrainingArguments,
    *,
    use_tmux: bool = False,
    tmux_session: str | None = None,
    tmux_auto_kill: bool = False,
) -> Tuple[OpenSlothConfig, TrainingArguments]:
    setup_envs(opensloth_config, training_args)
    multi_gpu = len(opensloth_config.devices) > 1
    if use_tmux and not multi_gpu:
        use_tmux = False
    if use_tmux and multi_gpu:
        cfg_path = _serialise_configs_to_temp(opensloth_config, training_args)
        session = tmux_session or f"os_train_{os.getpid()}"
        run_tmux_training(
            session_name=session,
            config_file=str(cfg_path),
            training_config=training_args,
            gpus=opensloth_config.devices,
            auto_kill=tmux_auto_kill,
        )
        return opensloth_config, training_args
    run_mp_training(
        gpus=opensloth_config.devices,
        opensloth_config=opensloth_config,
        training_config=training_args,
    )
    return opensloth_config, training_args

def run_prepare_data(config: dict) -> str:
    method = config.get("training_type", "sft")
    if method == "grpo":
        import importlib.util, pathlib
        prep_path = pathlib.Path(__file__).resolve().parent.parent / "prepare_dataset" / "prepare_grpo.py"
        spec = importlib.util.spec_from_file_location("_grpo_prep", prep_path)
        if spec is None or spec.loader is None:
            raise RuntimeError("Could not locate prepare_grpo.py")
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)  # type: ignore
        preparer = getattr(module, "GRPODatasetPreparer")()
    else:
        from opensloth.dataset import QwenDatasetPreparer, GemmaDatasetPreparer  # type: ignore
        model_name = config.get("tok_name", "").lower()
        preparer = GemmaDatasetPreparer() if "gemma" in model_name else QwenDatasetPreparer()
    output_dir = preparer.run_with_config(config)
    return output_dir

__all__ = ["run_training", "run_prepare_data"]
