"""Public programmatic API for OpenSloth."""
from __future__ import annotations

from pathlib import Path
from typing import Tuple
import json
import tempfile
import textwrap
import os
import pprint
import sys
import subprocess

from opensloth.opensloth_config import OpenSlothConfig, TrainingArguments
from opensloth.scripts.opensloth_trainer import (
    run_mp_training,
    setup_envs,
    run_tmux_training,
)

def _serialise_configs_to_temp(opensloth_config: OpenSlothConfig, training_args: TrainingArguments) -> Path:
    tmp_dir = Path(tempfile.mkdtemp(prefix="opensloth_cli_"))
    cfg_path = tmp_dir / "_tmux_config.py"
    code = textwrap.dedent(
        f"""# Auto-generated by OpenSloth API (tmux launch)
import json
from opensloth.opensloth_config import OpenSlothConfig, TrainingArguments
_opensloth_cfg_json = r'''{json.dumps(opensloth_config.model_dump())}'''
_training_args_json = r'''{json.dumps(training_args.model_dump())}'''
opensloth_config = OpenSlothConfig(**json.loads(_opensloth_cfg_json))
training_config = TrainingArguments(**json.loads(_training_args_json))
"""
    )
    cfg_path.write_text(code)
    return cfg_path

def _generate_training_script(
    opensloth_config: OpenSlothConfig, 
    training_args: TrainingArguments
) -> str:
    """Generates a standalone Python script from config objects."""
    
    # Convert Pydantic models to dictionaries
    opensloth_config_dict = opensloth_config.model_dump()
    training_args_dict = training_args.model_dump()

    # Use pprint to create a nicely formatted, human-readable string
    opensloth_config_str = pprint.pformat(opensloth_config_dict, indent=4, width=100)
    training_args_str = pprint.pformat(training_args_dict, indent=4, width=100)

    script_template = f"""# =============================================================================
# THIS SCRIPT WAS AUTO-GENERATED BY THE OPENSLOTH CLI
# =============================================================================
#
# It contains the exact configuration for a training run, making it fully
# reproducible and easy to modify for future experiments.
#
# To run this script directly:
# python train.py
#
# =============================================================================

from opensloth.opensloth_config import OpenSlothConfig, TrainingArguments
from opensloth.scripts.opensloth_trainer import setup_envs, run_mp_training

# --- Configuration Dictionaries ---

opensloth_config_dict = {opensloth_config_str}

training_args_dict = {training_args_str}


# --- Main Execution ---

if __name__ == "__main__":
    # Load configs from dictionaries
    opensloth_config = OpenSlothConfig(**opensloth_config_dict)
    training_config = TrainingArguments(**training_args_dict)

    # Setup environment and run training
    setup_envs(opensloth_config, training_config)
    run_mp_training(opensloth_config.devices, opensloth_config, training_config)

    print("\\n🎉 Training script finished successfully! ✨")
"""
    return script_template

def run_training(
    opensloth_config: OpenSlothConfig,
    training_args: TrainingArguments,
    *,
    use_tmux: bool = False,
    tmux_session: str | None = None,
    tmux_auto_kill: bool = False,
) -> Tuple[OpenSlothConfig, TrainingArguments]:
    setup_envs(opensloth_config, training_args)
    multi_gpu = len(opensloth_config.devices) > 1

    if use_tmux and not multi_gpu:
        use_tmux = False
    if use_tmux and multi_gpu:
        # Set USE_TMUX environment variable for tmux mode
        os.environ["USE_TMUX"] = "1"
        cfg_path = _serialise_configs_to_temp(opensloth_config, training_args)
        session = tmux_session or f"os_train_{os.getpid()}"
        run_tmux_training(
            session_name=session,
            config_file=str(cfg_path),
            training_config=training_args,
            gpus=opensloth_config.devices,
            auto_kill=tmux_auto_kill,
        )
        return opensloth_config, training_args
    # --- Generate-Then-Execute Path ---
    output_dir = Path(training_args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    script_path = output_dir / "train.py"

    print(f"⚙️ Generating standalone training script -> {script_path}")
    script_content = _generate_training_script(opensloth_config, training_args)
    script_path.write_text(script_content)

    print(f"🚀 Executing generated script...")
    # Use sys.executable to ensure the same Python env is used
    process = subprocess.run([sys.executable, str(script_path)], check=True)
    
    if process.returncode == 0:
        print(f"✅ Training process completed successfully.")
    else:
        print(f"❌ Training process failed with exit code {process.returncode}.")
    return opensloth_config, training_args

def run_prepare_data(config: dict) -> str:
    method = config.get("training_type", "sft")
    if method == "grpo":
        import importlib.util, pathlib
        # prepare_grpo.py lives at repository_root/prepare_dataset/prepare_grpo.py (not inside src/opensloth)
        repo_root = pathlib.Path(__file__).resolve().parents[2]
        prep_path = repo_root / "prepare_dataset" / "prepare_grpo.py"
        spec = importlib.util.spec_from_file_location("_grpo_prep", prep_path)
        if spec is None or spec.loader is None:
            raise RuntimeError("Could not locate prepare_grpo.py")
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)  # type: ignore
        preparer = getattr(module, "GRPODatasetPreparer")()
    else:
        from opensloth.dataset import QwenDatasetPreparer, GemmaDatasetPreparer  # type: ignore
        model_name = config.get("tok_name", "").lower()
        preparer = GemmaDatasetPreparer() if "gemma" in model_name else QwenDatasetPreparer()
    output_dir = preparer.run_with_config(config)
    return output_dir

__all__ = ["run_training", "run_prepare_data"]
